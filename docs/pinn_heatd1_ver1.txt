import os
import sys

# 1つ上(pde_engine)をパスに追加して C++ モジュールを import できるようにする
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn

import heat1d_cpp  # C++ソルバ（真値用）


# ============================
#  問題設定
# ============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

L = 1.0
alpha = 0.01
T_final = 0.4       # 最終時刻（C++側と合わせる）
Nx_cpp = 101
dt_cpp = 0.0005
steps_cpp = int(T_final / dt_cpp)  # 0.4 / 0.0005 = 800

# 初期条件（C++と同じガウス）
def initial_condition(x: torch.Tensor) -> torch.Tensor:
    return torch.exp(-((x - 0.5) ** 2) * 100.0)


# ============================
#  PINN モデル定義
# ============================
class MLP(nn.Module):
    def __init__(self, in_dim=2, out_dim=1, hidden_dim=64, num_layers=4):
        super().__init__()
        layers = []

        dims = [in_dim] + [hidden_dim] * (num_layers - 1) + [out_dim]
        for i in range(len(dims) - 2):
            layers.append(nn.Linear(dims[i], dims[i + 1]))
            layers.append(nn.Tanh())  # PINN では tanh が定番
        layers.append(nn.Linear(dims[-2], dims[-1]))

        self.net = nn.Sequential(*layers)

    def forward(self, x, t):
        # x, t: (N, 1)
        inputs = torch.cat([x, t], dim=1)
        return self.net(inputs)


model = MLP().to(device)


# ============================
#  損失関数の定義
# ============================
def pinn_loss(model):
    # --- PDE 残差用の点（内部点） ---
    N_r = 1000
    x_r = torch.rand(N_r, 1, device=device) * L        # (0, L)
    t_r = torch.rand(N_r, 1, device=device) * T_final  # (0, T)
    x_r.requires_grad_(True)
    t_r.requires_grad_(True)

    u_r = model(x_r, t_r)  # (N_r, 1)

    # u_t, u_xx を自動微分で計算
    ones = torch.ones_like(u_r)

    # du/dt
    u_t = torch.autograd.grad(
        u_r, t_r, grad_outputs=ones,
        create_graph=True, retain_graph=True
    )[0]

    # du/dx
    u_x = torch.autograd.grad(
        u_r, x_r, grad_outputs=ones,
        create_graph=True, retain_graph=True
    )[0]

    # d^2u/dx^2
    u_xx = torch.autograd.grad(
        u_x, x_r, grad_outputs=torch.ones_like(u_x),
        create_graph=True, retain_graph=True
    )[0]

    # 熱方程式: u_t - alpha * u_xx = 0
    residual = u_t - alpha * u_xx
    loss_pde = (residual ** 2).mean()

    # --- 初期条件ロス ---
    N_ic = 200
    x_ic = torch.rand(N_ic, 1, device=device) * L
    t_ic = torch.zeros(N_ic, 1, device=device)  # t = 0
    u_ic_pred = model(x_ic, t_ic)
    u_ic_true = initial_condition(x_ic)
    loss_ic = ((u_ic_pred - u_ic_true) ** 2).mean()

    # --- 境界条件ロス（両端固定） ---
    N_bc = 200
    t_bc = torch.rand(N_bc, 1, device=device) * T_final

    x_left = torch.zeros(N_bc, 1, device=device)       # x=0
    x_right = torch.ones(N_bc, 1, device=device) * L   # x=L

    u_left = model(x_left, t_bc)
    u_right = model(x_right, t_bc)

    loss_bc = (u_left ** 2).mean() + (u_right ** 2).mean()

    # 重みはとりあえず全部1.0からスタート
    loss = loss_pde + loss_ic + loss_bc
    return loss, loss_pde, loss_ic, loss_bc


# ============================
#  学習ループ
# ============================
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

num_epochs = 5000  # 時間かかるようなら小さくしてOK

for epoch in range(1, num_epochs + 1):
    optimizer.zero_grad()
    loss, lpde, lic, lbc = pinn_loss(model)
    loss.backward()
    optimizer.step()

    if epoch % 500 == 0 or epoch == 1:
        print(
            f"Epoch {epoch}/{num_epochs} "
            f"loss={loss.item():.4e} "
            f"(PDE={lpde.item():.4e}, IC={lic.item():.4e}, BC={lbc.item():.4e})"
        )


# ============================
#  学習後の評価 & C++ 真値との比較
# ============================

# 1. PINN の最終時刻 T_final での解
Nx_eval = 201
x_eval = torch.linspace(0.0, L, Nx_eval, device=device).view(-1, 1)
t_eval = torch.ones_like(x_eval) * T_final

with torch.no_grad():
    u_pinn = model(x_eval, t_eval).cpu().numpy().flatten()

x_eval_np = x_eval.cpu().numpy().flatten()

# 2. C++ ソルバによる真値（同じ T_final）
x_cpp, u_cpp = heat1d_cpp.solve_heat_1d(
    Nx=Nx_cpp,
    L=L,
    alpha=alpha,
    dt=dt_cpp,
    steps=steps_cpp,
)
x_cpp = np.array(x_cpp)
u_cpp = np.array(u_cpp)

# 3. C++ 解を PINN の評価点 x_eval_np 上に線形補間
u_cpp_interp = np.interp(x_eval_np, x_cpp, u_cpp)

# 4. 誤差を計算（L2 / L∞ ノルム）
error = u_pinn - u_cpp_interp
l2 = np.sqrt(np.mean(error**2))
linf = np.max(np.abs(error))

print(f"[Evaluation at T = {T_final}]")
print(f"  L2  error = {l2:.4e}")
print(f"  Linf error = {linf:.4e}")

# 5. プロット（これまで通り）
plt.figure()
plt.plot(x_cpp, u_cpp, label="C++ solver (true)", linewidth=2)
plt.plot(x_eval_np, u_pinn, "--", label="PINN", linewidth=2)
plt.xlabel("x")
plt.ylabel("u(x, T_final)")
plt.title("1D Heat Equation: C++ vs PINN")
plt.legend()
plt.grid(True)
plt.show()
